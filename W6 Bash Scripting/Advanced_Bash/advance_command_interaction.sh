# Over the past few videos, we've learned a lot about how to do things in the Linux command line and in Bash scripts. We will now look at a couple of interesting applications for all these Bash scripting powers that we just learned to put all this new knowledge into action. Let's go back to our old friend, the system log file located in var/log/syslog. The system log file contains a trove of information about what's going on in the system. So it's really important to learn how to get information out of it. Let's use the tail command to look at the last 10 lines from the file right now.
tail /var/log/syslog
# The load lines we see follow a similar pattern. First, they include the date and time of when the entry was added to the file, then the name of the computer, then the name and PID of the process that trigger the event and finally, the actual event that's being logged. Take a second and look at those lines. Say that we had a computer that was under significant load but we didn't know why, and to find out we wanted to check what events are being logged the most or Syslog. To do that we need to extract the part of the line that has the actual event without the date and time. We can use a command called cut to help us with that. This command, let's us take only bits of each line using a field delimiter. In this example, we can split the line using spaces. That would look something like this.
tail /var/log/syslog | cut -d' ' -f5-
# In our example, we're passing dash d space to cut to tell it that we want to use a space as a delimiter, and dash f5 dash that tell it that we want to print the field number 5 and everything that comes after it. With that, we remove the date and the name of the computer keeping only the process and the event message, snip snip. Now that we have the information that we care about, we can pipe this to the same pipeline of commands that we saw in an earlier video to find out the lines that are repeated the most; like this.
cut -d' ' -f5- /var/log/syslog | sort | uniq -c | sort -nr | head
# As you can see, we've chained together a bunch of commands so that we get the most repetitive lines in our Syslog file. There are more files in var/log that we might be interested in. So we can use a for loop to iterate over each of the log files in var/log and get the most repeated lines in each of them. I know what you're thinking. This sounds like it's getting a little bit too complex for a one-line chain of commands. We're better off putting this into a bash script, something like this. In this script we process all files in var/log that end in log. We then print the name of the file that we're processing and then use the same group of commands as before to print the top five lines in each file. Ready? Let's execute it and see this in action.
cat toploglines.sh
./toploglines.sh
# Nice. Our script shows us the most common lines on each file in var/log. There are a lot of files in there, and with that, we wrap up our introduction to Bash scripting. Amazing work. Now that you have scripting skills in both python and bash, you might be wondering when to use one versus the other. Well, we'll talk about that in our next video. See you there.